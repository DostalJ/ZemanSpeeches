{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from czech_stemmer_rev0.czech_stemmer import cz_stem\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = read_csv(filepath_or_buffer='./Zeman/speeches.csv', sep=';')\n",
    "df2 = read_csv(filepath_or_buffer='./Trump/speeches.csv', sep=';')\n",
    "df1 = df1.dropna(axis=0, how='any')\n",
    "df2 = df2.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Occurrences of čína: 31.851629\n",
      "Occurrences of trump: 2.171702\n",
      "Occurrences of putin: 3.981454\n",
      "Occurrences of česko: 357.606929\n",
      "Occurrences of eu: 8.324858\n",
      "Occurrences of evropa: 31.127729\n",
      "Occurrences of evropska: 104.241696\n",
      "Occurrences of uprchlíci: 7.600957\n",
      "Occurrences of islám: 0.000000\n",
      "Occurrences of hranice: 21.717020\n",
      "Occurrences of zeď: 0.000000\n",
      "Occurrences of skvělé: 22.802871\n",
      "Occurrences of národ: 77.095421\n",
      "Occurrences of německo: 51.396947\n",
      "Occurrences of terorismus: 22.802871\n",
      "----------------------------------------\n",
      "Occurrences of china: 42.194093\n",
      "Occurrences of trump: 21.097046\n",
      "Occurrences of putin: 0.000000\n",
      "Occurrences of czech: 0.000000\n",
      "Occurrences of eu: 0.000000\n",
      "Occurrences of europe: 42.194093\n",
      "Occurrences of european: 0.000000\n",
      "Occurrences of refugee: 21.097046\n",
      "Occurrences of islam: 0.000000\n",
      "Occurrences of borders: 42.194093\n",
      "Occurrences of wall: 21.097046\n",
      "Occurrences of great: 126.582278\n",
      "Occurrences of nation: 400.843882\n",
      "Occurrences of germany: 0.000000\n",
      "Occurrences of terrorism: 105.485232\n"
     ]
    }
   ],
   "source": [
    "cz_words = ['čína', 'trump', 'putin', 'česko', 'eu', 'evropa', 'evropska', 'uprchlíci', 'islám', 'hranice', 'zeď', 'skvělé', 'národ', 'německo', 'terorismus']\n",
    "en_words = ['china', 'trump', 'putin', 'czech', 'eu', 'europe', 'european', 'refugee', 'islam', 'borders', 'wall', 'great', 'nation', 'germany', 'terrorism']\n",
    "\n",
    "print('-'*40)\n",
    "text = ' '.join(df1['text'].values.tolist())\n",
    "tokenized_text = [w.lower() for w in word_tokenize(text)]\n",
    "stemmed_text = [cz_stem(w) for w in tokenized_text]\n",
    "for w in cz_words:\n",
    "    print('Occurrences of {:s}: {:f}'.format(\n",
    "        w, 100000 * stemmed_text.count(cz_stem(w)) / len(stemmed_text)))\n",
    "\n",
    "print('-'*40)\n",
    "text = ' '.join(df2['text'].values.tolist())\n",
    "tokenized_text = [w.lower() for w in word_tokenize(text)]\n",
    "ps = PorterStemmer()\n",
    "stemmed_text = [ps.stem(w) for w in tokenized_text]\n",
    "for w in en_words:\n",
    "    print('Occurrences of {:s}: {:f}'.format(\n",
    "        w, 100000 * stemmed_text.count(ps.stem(w)) / len(stemmed_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = []\n",
    "for index, row in df1.iterrows():\n",
    "    text = [cz_stem(w.lower()) for w in word_tokenize(row['text'])]\n",
    "    if cz_stem('čína') in text:\n",
    "        china.append(True)\n",
    "    else:\n",
    "        china.append(False)\n",
    "df1['china'] = china\n",
    "china = []\n",
    "for index, row in df2.iterrows():\n",
    "    text = [ps.stem(w.lower()) for w in word_tokenize(row['text'])]\n",
    "    if ps.stem('china') in text:\n",
    "        china.append(True)\n",
    "    else:\n",
    "        china.append(False)\n",
    "df2['china'] = china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0959821428571\n",
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "print(df1['china'].mean())\n",
    "print(df2['china'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
