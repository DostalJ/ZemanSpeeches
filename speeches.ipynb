{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep  # sleeping\n",
    "from requests import get  # downloading page source\n",
    "from bs4 import BeautifulSoup  # BeautifulSoup for processing html source pages\n",
    "from pandas import DataFrame  # DataFrame for storing and manipulating data\n",
    "from pandas import to_datetime  # convert string to datetime\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException  # selenium alert exception\n",
    "from selenium.webdriver import Chrome  # Chrome browser driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download list of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening browser.\n",
      "Message: unknown error: Element <a class=\"read_more_big center mouse\" id=\"dalsistrankabtn\" onclick=\"newsAjax('clanky');\" title=\"...\" tabindex=\"1\">NAČÍST DALŠÍ ČLÁNKY</a> is not clickable at point (368, 698). Other element would receive the click: <p>...</p>\n",
      "  (Session info: chrome=58.0.3029.110)\n",
      "  (Driver info: chromedriver=2.29.461585 (0be2cd95f834e9ee7c46bcc7cf405b483f5ae83b),platform=Mac OS X 10.12.5 x86_64)\n",
      "\n",
      "Closing browser.\n"
     ]
    }
   ],
   "source": [
    "def click(id_, driver, sleep_time=0.5):\n",
    "    \"\"\"\n",
    "    Clicks button with given id.\n",
    "    Args:\n",
    "        id_: id of the buttton\n",
    "        driver: browser\n",
    "        sleep_time: sleeps twice (after finding button and after clicking)\n",
    "    \"\"\"\n",
    "    button = driver.find_element_by_id(id_=id_)  # find button\n",
    "    sleep(sleep_time)  # sleep\n",
    "    button.click()  # click\n",
    "    sleep(sleep_time)  # sleep\n",
    "    \n",
    "def download_page_with_articles(url):\n",
    "    \"\"\"\n",
    "    Clicks on button 'dalsistrankabtn' until all articles listed.\n",
    "    Args:\n",
    "        url: url to page with list of articles\n",
    "    Returns:\n",
    "        page_source: html source of whole page\n",
    "    \"\"\"\n",
    "    print('Opening browser.')\n",
    "    browser = Chrome(executable_path=\"./chromedriver\")  # open browser\n",
    "    browser.get(url)  # get page\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # click on button for next articles\n",
    "            click(id_='dalsistrankabtn', driver=browser)\n",
    "        except UnexpectedAlertPresentException:  # if all articles listed\n",
    "            alert = browser.switch_to_alert()\n",
    "            alert.accept()  # accept the alert window\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            sleep(30)\n",
    "    print('Closing browser.')\n",
    "    page_source = browser.page_source  # get source page\n",
    "    browser.quit()\n",
    "    return page_source\n",
    "\n",
    "URL = 'http://www.zemanmilos.cz/cz/'\n",
    "page_source = download_page_with_articles(url=URL + 'clanky/')\n",
    "\n",
    "def process_page(page_source):\n",
    "    \"\"\"\n",
    "    From source page with all articles get title, date, link\n",
    "    Args:\n",
    "        page_source: html source of the page with articles\n",
    "    Returns:\n",
    "        df: pandas DataFrame with columns=['date', 'link', 'title']\n",
    "    \"\"\"\n",
    "    page = BeautifulSoup(page_source, 'lxml')  # process\n",
    "\n",
    "    # find all articles\n",
    "    articles = page.find_all(name='div', attrs={'class': 'news_view'})\n",
    "    \n",
    "    df = DataFrame(columns=['date', 'link', 'title'])  # create DataFrame\n",
    "    speech_index = 0\n",
    "    for article in articles:  # for all listed articles\n",
    "        # date article was published\n",
    "        date = article.span.text[-10:]\n",
    "        # link to article\n",
    "        link = 'http://www.zemanmilos.cz/' + article.h3.a['href']\n",
    "        # title of the article\n",
    "        title = article.h3.a.text\n",
    "\n",
    "        # if the article is 'Projev' and has acceptable data\n",
    "        if 'Projev' in title and int(date[-4:]) > 0:\n",
    "            new_row = DataFrame(data={'date': date,\n",
    "                                      'link': link,\n",
    "                                      'title': title},\n",
    "                                index=[speech_index])\n",
    "            df = df.append(new_row)  # add to DataFrame\n",
    "            speech_index += 1\n",
    "\n",
    "    # parse date (only date, without time)\n",
    "    df['date'] = to_datetime(arg=df['date'], format='%d.%M.%Y').dt.floor('d')\n",
    "    return df\n",
    "df = process_page(page_source=page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download each speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading each article...\n",
      "Exception for link http://www.zemanmilos.cz/cz/clanky/projev-prezidenta-republiky-na-14-rocniku-mezinarodni-konference--investment-&-business-forum--480054.htm: 'NoneType' object has no attribute 'text'\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def download_articles(df):\n",
    "    \"\"\"\n",
    "    Download text of each article.\n",
    "    Args:\n",
    "        df: pandas DataFrame with columns=['date', 'link', 'title']\n",
    "    Returns:\n",
    "        df: pandas DataFrame with columns=['date', 'link', 'title', 'text']\n",
    "    \"\"\"\n",
    "    print('Downloading each article...')\n",
    "    speeches = []\n",
    "    for speech_link in df['link'].values:  # for every link to article\n",
    "        try:\n",
    "            # get article source page\n",
    "            req = get(url=speech_link).text.encode(encoding='utf8')\n",
    "            # convert to html\n",
    "            page = BeautifulSoup(markup=req, features='lxml')\n",
    "            # find text of the speech\n",
    "            speech = page.find(name='div', attrs={'class': 'wrap_detail'}).text\n",
    "        except Exception as e:  # if exception occurs\n",
    "            print('Exception for link {:s}:'.format(speech_link),  e)\n",
    "        speech = speech.replace(u'\\n', u'')  # replace newline tag\n",
    "        speech = speech.replace(u'\\xa0', u' ')  # replace hard space tag\n",
    "        speeches.append(speech)\n",
    "    df['text'] = speeches  # add to DataFrame\n",
    "    return df\n",
    "df = download_articles(df=df)\n",
    "print('Done.')\n",
    "\n",
    "# save to csv\n",
    "df.to_csv('./speeches.csv', encoding='utf8', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
